{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "collapsed_sections": [
        "ls6d5B5VSU66",
        "Z_zR-QZgSY5y",
        "v8Mbx1aAUTvK"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# UCI Introduction to Machine Learning\n",
        "**Day 3: Convolutional Neural Networks**\n",
        "\n",
        "\n",
        "Notebook adapted by Gage DeZoort from a similar notebook offered in Princeton University's [Introduction to Machine Learning Wintersession course](https://github.com/PrincetonUniversity/intro_machine_learning/tree/main).\n",
        "\n",
        "\n",
        "\n",
        "<a href=\"https://colab.research.google.com/github/GageDeZoort/intro_ml_uci/blob/main/day_3/intro_to_ML_day_3_cnns.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ],
      "metadata": {
        "id": "zpCkWYWdmgbk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. The CIFAR-10 Dataset\n"
      ],
      "metadata": {
        "id": "ls6d5B5VSU66"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The goal of this notebook is to demo image classification in the **CIFAR10** dataset using **convolutional neural networks (CNNs)**.\n",
        "\n",
        "If you'd like to use a GPU, click on `Runtime` (in the Colab toolbar above) then `Change runtime type` and select `T4 GPU`.\n"
      ],
      "metadata": {
        "id": "2YtdceqGWzdv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "7LzSJGvKV7JE"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "device = \"cuda\" # or \"cuda\" if you want to use the GPU!"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The [**CIFAR-10 dataset**](https://www.cs.toronto.edu/~kriz/cifar.html) is a classic benchmark for image classification.  \n",
        "“CIFAR” stands for **Canadian Institute for Advanced Research**, and “10” refers to its **10 image categories**.\n",
        "\n",
        "---\n",
        "\n",
        "**Key properties:**\n",
        "- **10 classes:** airplane, automobile, bird, cat, deer, dog, frog, horse, ship, truck  \n",
        "- **6,000 images per class** → **60,000 images total**  \n",
        "- **Image size:** 32×32 pixels, RGB color (so each image has shape **32×32×3**)  \n",
        "- Standard split: 50,000 for training, 10,000 for testing  \n",
        "\n",
        "---\n",
        "\n",
        "Each example in CIFAR-10 is a small, low-resolution color photo representing one of the 10 object categories.  \n",
        "We’ll train a neural network to recognize which class each image belongs to.\n",
        "\n",
        "Here’s a quick visual preview\n",
        "\n",
        "<p align=\"center\">\n",
        "  <img src=\"https://raw.githubusercontent.com/GageDeZoort/intro_ml_uci/main/day_3/images/rgb_images.png\" width=\"300\">\n",
        "</p>\n"
      ],
      "metadata": {
        "id": "EeR8TYPic_OJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**`torchvision`** is a companion library to [PyTorch](https://pytorch.org/) that provides tools, datasets, and models for **computer vision** tasks.\n",
        "\n",
        "---\n",
        "\n",
        "**Core modules include:**\n",
        "- `torchvision.datasets` → standardized datasets for quick loading  \n",
        "- `torchvision.transforms` → image preprocessing and augmentation tools  \n",
        "- `torchvision.models` → pretrained CNN and vision transformer architectures  \n",
        "- `torchvision.utils` → helper functions for visualizing and saving images  "
      ],
      "metadata": {
        "id": "r6OxpA3BRYm4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# transform RGB features from [0,1]x3 to [-1,1]x3\n",
        "transform = transforms.Compose(\n",
        "  [ # image = (image - mean) / std\n",
        "      transforms.ToTensor(),\n",
        "      transforms.Normalize(\n",
        "          (0.5, 0.5, 0.5), # means\n",
        "          (0.5, 0.5, 0.5) # stds\n",
        "      )\n",
        "   ]\n",
        ")\n",
        "\n",
        "# grab the train and test sets\n",
        "trainset = torchvision.datasets.CIFAR10(\n",
        "    root='./data',\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=transform\n",
        "  )\n",
        "testset = torchvision.datasets.CIFAR10(\n",
        "    root='./data',\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=transform\n",
        ")"
      ],
      "metadata": {
        "id": "zUWR3zazYJE1",
        "outputId": "27dcb637-54d4-4630-80a0-f1b9de8974c2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170M/170M [00:13<00:00, 12.4MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "With the datasets loaded, we can use the `DataLoader` class provided by torch to conveniently load up random batches of data."
      ],
      "metadata": {
        "id": "JPu-y0Kdf-fE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 4\n",
        "\n",
        "# feed the train/test sets into data loaders\n",
        "trainloader = torch.utils.data.DataLoader(\n",
        "    trainset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        ")\n",
        "testloader = torch.utils.data.DataLoader(\n",
        "    testset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False,\n",
        ")"
      ],
      "metadata": {
        "id": "zTZiRyjMf1sm"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "With our loaders in place, let's plot one batch of data."
      ],
      "metadata": {
        "id": "BG06xqjXgTNM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def imshow(img):\n",
        "  img = img / 2 + 0.5  # unnormalize\n",
        "  plt.imshow(np.transpose(img.cpu().numpy(), (1, 2, 0)))\n",
        "  plt.show()\n",
        "\n",
        "# get some random training images\n",
        "dataiter = iter(trainloader)\n",
        "images, labels = next(dataiter)\n",
        "\n",
        "# show images\n",
        "imshow(torchvision.utils.make_grid(images))\n",
        "\n",
        "# truth labels\n",
        "classes = (\n",
        "    'plane', 'car', 'bird', 'cat', 'deer',\n",
        "    'dog', 'frog', 'horse', 'ship', 'truck'\n",
        ")\n",
        "print(' '.join(f'{classes[labels[j]]:5s}' for j in range(batch_size)))"
      ],
      "metadata": {
        "id": "iojIsXgTaoz_",
        "outputId": "cd72ddf5-2976-4b48-bb5f-48e5344c6e1d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 210
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "horse dog   horse horse\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> **EXERCISE 1**: Print the shape of `images` above. Does it make sense?"
      ],
      "metadata": {
        "id": "NvG3GCAnSJPG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# EXERCISE 1\n",
        "images.shape # [batch_size, RGB, ix, iy]\n",
        "\n"
      ],
      "metadata": {
        "id": "bvsoy_YxRwJP",
        "outputId": "07591b00-300f-495f-959f-505d432dc739",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([4, 3, 32, 32])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> If you only plot one feature per-pixel instead of 3, it will be interpreted as a greyscale image. Try plotting only one of the RGB features."
      ],
      "metadata": {
        "id": "CsnCJnEUT-IJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# EXERCISE 1\n"
      ],
      "metadata": {
        "id": "oe5O6oE9TiBw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Image Classification with a CNN"
      ],
      "metadata": {
        "id": "Z_zR-QZgSY5y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Our next goal is to define a CNN to do the image classification. The CNN will be a `torch.nn.Module`, which is a generic class designed to hold neural network components. The `forward()` function of the network is the forward pass; everything called there will be used to transform the input data (using learnable weights) and produce a prediction."
      ],
      "metadata": {
        "id": "DoBtx2ayg_5d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Convolutional Layers**: Convolutional layers use **learnable filters** (also called **kernels**) to detect visual patterns in images. Each filter is a small matrix of **learnable weights** (e.g., 3x3 or 5x5) that slides across the image, computing the **elementwise product** of its weights and the underlying pixel values.\n",
        "\n",
        "During training, these filter weights are updated via backpropagation so they learn to respond to meaningful features — such as edges, textures, or object parts. Stacking many convolutional layers allows a network to build up increasingly abstract representations of an image, from low-level shapes to high-level concepts.\n",
        "\n",
        "There is a [wonderful Medium article](https://towardsdatascience.com/intuitively-understanding-convolutions-for-deep-learning-1f6f42faee1) that visualizes the process. Convolutional filters extract high level information from each RGB channel: ![Conv](https://miro.medium.com/v2/resize:fit:2000/format:webp/1*8dx6nxpUh2JqvYWPadTwMQ.gif \"conv\")\n",
        "\n",
        "Information extracted from each channel is summed at the output of each convolutional layer: ![ConvSum](https://miro.medium.com/v2/resize:fit:2000/format:webp/1*CYB2dyR3EhFs1xNLK8ewiA.gif \"conv-sum\")\n",
        "\n",
        "The filters are **learned** by the algorithm; the intuition is that they become \"detectors\" for certain image features. For exmaple, here's a nice example of a kernel filter that detects vertical lines (sourced from the Medium article): ![EdgeDetector](https://miro.medium.com/v2/resize:fit:2000/format:webp/1*wju0Urp6KpAT11wktTp5Sg.png \"edge-detector\")"
      ],
      "metadata": {
        "id": "8Ags5fltYkQ9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Pooling Layers** are designed to downsample images. Contrary to filters, they are *not* learnable, instead representing fixed operations. For example, a pooling layer say \"take the maximum value from each 3x3 grid of cells\".\n",
        "![Pooling](https://miro.medium.com/v2/resize:fit:588/format:webp/1*BMngs93_rm2_BpJFH2mS0Q.gif \"pooling\")\n",
        "\n",
        "Pooling is used to aggregate information and shape it in a useful way for downstream learning tasks.\n"
      ],
      "metadata": {
        "id": "cK8b64Afyf7V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, you will see **fully-connected layers**;\n",
        "these are the simple PyTorch `linear` layers we saw yesteday. After convolutional filters and pooling layers have been applied, the resulting data is flattened and passed through a simple fully connected network to produce classification scores."
      ],
      "metadata": {
        "id": "_xuxOWh0ykAU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        # Input image shape: [batch_size, 3, 32, 32]\n",
        "        #   - 3 channels (RGB)\n",
        "        #   - 32x32 pixels\n",
        "\n",
        "        # Conv layer 1:\n",
        "        #   - 3 input channels → 6 output channels (6 learned filters)\n",
        "        #   - Each filter is 3x5x5, where the RGB dimension (3) is summed over\n",
        "        # Output shape after conv1: [batch_size, 6, 28, 28]\n",
        "        #   → 5x5 filter size narrows the input dimensions by 2\n",
        "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=6, kernel_size=5, stride=1)\n",
        "\n",
        "        # Max pooling layer:\n",
        "        #   - 2x2 pooling with stride 2 → halves width and height\n",
        "        # Output shape after pool1: [batch_size, 6, 14, 14]\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        # Conv layer 2:\n",
        "        #   - 6 input channels → 16 output channels\n",
        "        #   - Each filter is 6x5x5, where the feature dimension (6) is summed over\n",
        "        # Output shape after conv2: [batch_size, 16, 10, 10]\n",
        "        #   → 5x5 filter narrows the input dimensions by 2\n",
        "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5, stride=1)\n",
        "\n",
        "        # In the forward function, we apply the pooling operation again\n",
        "        # Second pooling → halves 10x10 → 5x5\n",
        "        # Output shape after pool2: [batch_size, 16, 5, 5]\n",
        "\n",
        "        # Flattened size = 16 * 5 * 5 = 400 features per image\n",
        "        # Fully connected layers:\n",
        "        self.fc1 = nn.Linear(in_features=16 * 5 * 5, out_features=120)\n",
        "        self.fc2 = nn.Linear(in_features=120, out_features=84)\n",
        "        self.fc3 = nn.Linear(in_features=84, out_features=10)  # 10 classes for CIFAR-10\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Input: [batch_size, 3, 32, 32]\n",
        "        x = self.pool(F.relu(self.conv1(x)))  # → [batch_size, 6, 14, 14]\n",
        "        x = self.pool(F.relu(self.conv2(x)))  # → [batch_size, 16, 5, 5]\n",
        "        x = torch.flatten(x, 1)               # → [batch_size, 16*5*5] = [batch_size, 400]\n",
        "        x = F.relu(self.fc1(x))               # → [batch_size, 120]\n",
        "        x = F.relu(self.fc2(x))               # → [batch_size, 84]\n",
        "        x = self.fc3(x)                       # → [batch_size, 10] (class scores)\n",
        "        return x\n",
        "\n",
        "net = Net().to(device)\n",
        "print(net.conv1)"
      ],
      "metadata": {
        "id": "YB99ezb3f1ov",
        "outputId": "86894c87-232c-490c-f737-11358824f2e4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Stare carefully at the comments in the code above - this is the yoga of CNN dimension bookkeeping. One other word we haven't mentioned yet - the **stride** of the filters is by default `1`, which means they'll slide pixel-by-pixel across the image. However, that's not the only possibility!\n",
        "\n",
        "Here's a visual of what `stride=2` might look like:\n",
        "\n",
        "![stride2](https://upload.wikimedia.org/wikipedia/commons/b/b9/Convolution_arithmetic_-_No_padding_strides.gif \"stride2\")\n",
        "\n",
        "To put it carefully, in this image we're applying a 3x3 operation (either pooling or convolution) with stride 2."
      ],
      "metadata": {
        "id": "sRQxdZX3zoGo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercise 2\n",
        "(3 mins)  Knowing this, what is the shape of an image after the pooling stage? Can you make sense of the shapes provided to initialize `self.conv2`? What about the output of `self.conv2`?\n"
      ],
      "metadata": {
        "id": "jYaBCHEywWzb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image = images[0:1].to(device)\n",
        "print(\"Initial image shape:\", image.shape)\n",
        "image_conv1 = net.conv1(image)\n",
        "print(\"After conv1:\", image_conv1.shape)\n",
        "\n",
        "# TO-DO: pass image_conv1 to the pooling operator\n",
        "image_pool = net.pool(image_conv1)\n",
        "print(image_pool.shape)\n",
        "#[1,6,14,14]\n",
        "# TO-DO: pass image_pool to the conv2 operator\n",
        "image_conv2 = net.conv2(image_pool)\n",
        "print(image_conv2.shape)\n",
        "#[]"
      ],
      "metadata": {
        "id": "Kdv_fI7qyQ8q",
        "outputId": "5fc02953-071e-4bf3-aa28-a941851ec66e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial image shape: torch.Size([1, 3, 32, 32])\n",
            "After conv1: torch.Size([1, 6, 28, 28])\n",
            "torch.Size([1, 6, 14, 14])\n",
            "torch.Size([1, 16, 10, 10])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since this is a classification problem, we're going to optimize a cross entropy loss. Our strategy will be simple stochastic gradient descent."
      ],
      "metadata": {
        "id": "OmeVuPMBoxGt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
      ],
      "metadata": {
        "id": "1OL8WbC0apGr"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here's our training loop - it's fairly standard, so we won't comment too much. Let's press play and train the network!"
      ],
      "metadata": {
        "id": "21HB5nQlo1zR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(5):  # loop over the dataset multiple times\n",
        "\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        # get the inputs; data is a list of [inputs, labels]\n",
        "        inputs, labels = data[0].to(device), data[1].to(device)\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # print statistics\n",
        "        running_loss += loss.item()\n",
        "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
        "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}')\n",
        "            running_loss = 0.0\n",
        "\n",
        "print('Finished Training')"
      ],
      "metadata": {
        "id": "PP5Pspsto0Az",
        "outputId": "8c0fd8c6-e242-4801-a8cc-a72e5ecf9857",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1,  2000] loss: 2.190\n",
            "[1,  4000] loss: 1.818\n",
            "[1,  6000] loss: 1.657\n",
            "[1,  8000] loss: 1.542\n",
            "[1, 10000] loss: 1.501\n",
            "[1, 12000] loss: 1.451\n",
            "[2,  2000] loss: 1.377\n",
            "[2,  4000] loss: 1.361\n",
            "[2,  6000] loss: 1.295\n",
            "[2,  8000] loss: 1.310\n",
            "[2, 10000] loss: 1.258\n",
            "[2, 12000] loss: 1.253\n",
            "[3,  2000] loss: 1.176\n",
            "[3,  4000] loss: 1.169\n",
            "[3,  6000] loss: 1.188\n",
            "[3,  8000] loss: 1.184\n",
            "[3, 10000] loss: 1.139\n",
            "[3, 12000] loss: 1.141\n",
            "[4,  2000] loss: 1.078\n",
            "[4,  4000] loss: 1.067\n",
            "[4,  6000] loss: 1.090\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataiter = iter(testloader)\n",
        "test_data = next(dataiter)\n",
        "images, labels = test_data[0].to(device), test_data[1].to(device)\n",
        "\n",
        "# print images\n",
        "imshow(torchvision.utils.make_grid(images))\n",
        "print('GroundTruth: ', ' '.join(f'{classes[labels[j]]:5s}' for j in range(4)))\n"
      ],
      "metadata": {
        "id": "XspTScH6o4p0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "outputs = net(images)\n",
        "_, predicted = torch.max(outputs, 1)\n",
        "\n",
        "print('Predicted: ', ' '.join(f'{classes[predicted[j]]:5s}'\n",
        "                              for j in range(4)))"
      ],
      "metadata": {
        "id": "CO1hHBbS4zAm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "# since we're not training, we don't need to calculate the gradients for our outputs\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data[0].to(device), data[1].to(device)\n",
        "        # calculate outputs by running images through the network\n",
        "        outputs = net(images)\n",
        "        # the class with the highest energy is what we choose as prediction\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f'Accuracy of the network on the 10000 test images: {100 * correct // total} %')"
      ],
      "metadata": {
        "id": "voSXyQGX49Cl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prepare to count predictions for each class\n",
        "correct_pred = {classname: 0 for classname in classes}\n",
        "total_pred = {classname: 0 for classname in classes}\n",
        "\n",
        "# again no gradients needed\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data[0].to(device), data[1].to(device)\n",
        "        outputs = net(images)\n",
        "        _, predictions = torch.max(outputs, 1)\n",
        "        # collect the correct predictions for each class\n",
        "        for label, prediction in zip(labels, predictions):\n",
        "            if label == prediction:\n",
        "                correct_pred[classes[label]] += 1\n",
        "            total_pred[classes[label]] += 1\n",
        "\n",
        "\n",
        "# print accuracy for each class\n",
        "for classname, correct_count in correct_pred.items():\n",
        "    accuracy = 100 * float(correct_count) / total_pred[classname]\n",
        "    print(f'Accuracy for class: {classname:5s} is {accuracy:.1f} %')"
      ],
      "metadata": {
        "id": "mqbz3dEx8ucF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **EXERCISE 3**\n",
        "\n",
        "Can you improve these accuracies? Full notebook's worth of code reproduced below for convenience.\n"
      ],
      "metadata": {
        "id": "djn_HaxgEsQM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "device = \"cuda\" # or \"cuda\" if you want to use the GPU!\n",
        "\n",
        "classes = (\n",
        "    'plane', 'car', 'bird', 'cat', 'deer',\n",
        "    'dog', 'frog', 'horse', 'ship', 'truck'\n",
        ")\n",
        "\n",
        "# transform RGB features from [0,1]x3 to [-1,1]x3\n",
        "transform = transforms.Compose(\n",
        "  [ # image = (image - mean) / std\n",
        "      transforms.ToTensor(),\n",
        "      transforms.Normalize(\n",
        "          (0.5, 0.5, 0.5), # means\n",
        "          (0.5, 0.5, 0.5) # stds\n",
        "      )\n",
        "   ]\n",
        ")\n",
        "\n",
        "# grab the train and test sets\n",
        "trainset = torchvision.datasets.CIFAR10(\n",
        "    root='./data',\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=transform\n",
        "  )\n",
        "testset = torchvision.datasets.CIFAR10(\n",
        "    root='./data',\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=transform\n",
        ")\n",
        "\n",
        "batch_size = 4\n",
        "\n",
        "# feed the train/test sets into data loaders\n",
        "trainloader = torch.utils.data.DataLoader(\n",
        "    trainset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        ")\n",
        "testloader = torch.utils.data.DataLoader(\n",
        "    testset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False,\n",
        ")\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 6, 5, 1) # in_channels, out_channels, kernel_size, stride\n",
        "        self.pool = nn.MaxPool2d(2, 2) # kernel_size, stride\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5, 1) # in_channels, out_channels, kernel_size, stride\n",
        "        self.fc1 = nn.Linear(16 * 5 * 5, 120) # in_channels, out_channels\n",
        "        self.fc2 = nn.Linear(120, 84) # in_channels, out_channels\n",
        "        self.fc3 = nn.Linear(84, 10) # in_channels, out_channels\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x))) # learnable convolution, pool result\n",
        "        x = self.pool(F.relu(self.conv2(x))) # learnable convolution, pool result\n",
        "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
        "        x = F.relu(self.fc1(x)) # apply a fully-connected NN\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x # return classification scores\n",
        "\n",
        "net = Net().to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "for epoch in range(2):  # loop over the dataset multiple times\n",
        "\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        # get the inputs; data is a list of [inputs, labels]\n",
        "        inputs, labels = data[0].to(device), data[1].to(device)\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # print statistics\n",
        "        running_loss += loss.item()\n",
        "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
        "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}')\n",
        "            running_loss = 0.0\n",
        "\n",
        "print('Finished Training')\n",
        "\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data[0].to(device), data[1].to(device)\n",
        "        outputs = net(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f'Accuracy of the network on the 10000 test images: {100 * correct // total} %')\n",
        "\n",
        "# prepare to count predictions for each class\n",
        "correct_pred = {classname: 0 for classname in classes}\n",
        "total_pred = {classname: 0 for classname in classes}\n",
        "\n",
        "# again no gradients needed\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data[0].to(device), data[1].to(device)\n",
        "        outputs = net(images)\n",
        "        _, predictions = torch.max(outputs, 1)\n",
        "        # collect the correct predictions for each class\n",
        "        for label, prediction in zip(labels, predictions):\n",
        "            if label == prediction:\n",
        "                correct_pred[classes[label]] += 1\n",
        "            total_pred[classes[label]] += 1\n",
        "\n",
        "\n",
        "# print accuracy for each class\n",
        "for classname, correct_count in correct_pred.items():\n",
        "    accuracy = 100 * float(correct_count) / total_pred[classname]\n",
        "    print(f'Accuracy for class: {classname:5s} is {accuracy:.1f} %')"
      ],
      "metadata": {
        "id": "sthwvOOfFBd-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Solutions to Exercises\n"
      ],
      "metadata": {
        "id": "v8Mbx1aAUTvK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "#Exercise 1a\n",
        "\n",
        "# returns [4, 3, 32, 32], corresponding to [batch_size, RGB, ix, iy]\n",
        "images.shape\n",
        "```"
      ],
      "metadata": {
        "id": "jXVoKwbtUEwb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "# Exercise 1b\n",
        "\n",
        "# plot the \"R\" features only as greyscale\n",
        "imshow(torchvision.utils.make_grid(images[:,0:1,:,:]))\n",
        "```"
      ],
      "metadata": {
        "id": "jyd9WdGiUPBE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "Exercise 2\n",
        "\n",
        "# 2. (3 mins)  Knowing this, what is the shape of an image after the pooling stage? Can you make sense of the shapes provided to initialize `self.conv2`? What about the output of `self.conv2`?\n",
        "\n",
        "image = images[0:1].to(device)\n",
        "print(\"Initial image shape:\", image.shape)\n",
        "image_conv1 = net.conv1(image)\n",
        "print(\"After conv1:\", image_conv1.shape)\n",
        "image_pool = net.pool(image_conv1)\n",
        "print(\"After pooling:\", image_pool.shape)\n",
        "image_conv2 = net.conv2(image_pool)\n",
        "print(\"After conv2:\", image_conv2.shape)\n",
        "\n",
        "```"
      ],
      "metadata": {
        "id": "Ch48wZVrm0s6"
      }
    }
  ]
}